<!DOCTYPE html>












  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2"/>
<meta name="theme-color" content="#222">












<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />






















<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=6.3.0" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.3.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.3.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.3.0">


  <link rel="mask-icon" href="/images/logo.svg?v=6.3.0" color="#222">









<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '6.3.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: 'J3OX6892F7',
      apiKey: '38852eb9095216f8f2ada575a06a9cfc',
      indexName: 'Blog',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="CDH版本的spark阉割了spark-sql,可以重新编译cloudera/spark,或者直接在启动时添加所缺失的jar包  操作系统:SUSE11 SP3Spark版本:SPARK2-2.1.0.cloudera1-1.cdh5.7.0.p0.120904CDH版本:CDH5.10.041使用root用户对集群进行部署 直接添加所缺jar包下载Apache版Spark解压后找到jars/目录">
<meta property="og:type" content="article">
<meta property="og:title" content="spark-sql添加">
<meta property="og:url" content="https://nameless13.github.io/CDH/Error/[Spark]Spark-sql 添加.html">
<meta property="og:site_name" content="Nameless13">
<meta property="og:description" content="CDH版本的spark阉割了spark-sql,可以重新编译cloudera/spark,或者直接在启动时添加所缺失的jar包  操作系统:SUSE11 SP3Spark版本:SPARK2-2.1.0.cloudera1-1.cdh5.7.0.p0.120904CDH版本:CDH5.10.041使用root用户对集群进行部署 直接添加所缺jar包下载Apache版Spark解压后找到jars/目录">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2018-05-29T15:19:59.312Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="spark-sql添加">
<meta name="twitter:description" content="CDH版本的spark阉割了spark-sql,可以重新编译cloudera/spark,或者直接在启动时添加所缺失的jar包  操作系统:SUSE11 SP3Spark版本:SPARK2-2.1.0.cloudera1-1.cdh5.7.0.p0.120904CDH版本:CDH5.10.041使用root用户对集群进行部署 直接添加所缺jar包下载Apache版Spark解压后找到jars/目录">






  <link rel="canonical" href="https://nameless13.github.io/CDH/Error/[Spark]Spark-sql 添加.html"/>



<script type="text/javascript" id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>spark-sql添加 | Nameless13</title>
  









  <noscript>
  <style type="text/css">
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion {
      .logo-line-before i { left: initial; }
      .logo-line-after i { right: initial; }
    }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Nameless13</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">
    <a href="/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-home"></i> <br />首页</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">
    <a href="/categories/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-th"></i> <br />分类</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">
    <a href="/archives/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />归档</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-about">
    <a href="/about/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-user"></i> <br />关于</a>
  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />搜索</a>
        </li>
      
    </ul>
  

  
    

  

  
    <div class="site-search">
      
  
  <div class="algolia-popup popup search-popup">
    <div class="algolia-search">
      <div class="algolia-search-input-icon">
        <i class="fa fa-search"></i>
      </div>
      <div class="algolia-search-input" id="algolia-search-input"></div>
    </div>

    <div class="algolia-results">
      <div id="algolia-stats"></div>
      <div id="algolia-hits"></div>
      <div id="algolia-pagination" class="algolia-pagination"></div>
    </div>

    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
  </div>




    </div>
  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://nameless13.github.io/CDH/Error/[Spark]Spark-sql 添加.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Nameless13">
      <meta itemprop="description" content="─=≡Σ((( つ•̀ω•́)つ，大数据运维工程狮，90后">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Nameless13">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">spark-sql添加
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2017-07-12 00:00:00" itemprop="dateCreated datePublished" datetime="2017-07-12T00:00:00+08:00">2017-07-12</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2018-05-29 23:19:59" itemprop="dateModified" datetime="2018-05-29T23:19:59+08:00">2018-05-29</time>
              
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/CDH/" itemprop="url" rel="index"><span itemprop="name">CDH</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/CDH/Error/" itemprop="url" rel="index"><span itemprop="name">Error</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>CDH版本的spark阉割了spark-sql,可以重新编译cloudera/spark,或者直接在启动时添加所缺失的jar包</p>
<blockquote>
<p>操作系统:SUSE11 SP3<br>Spark版本:SPARK2-2.1.0.cloudera1-1.cdh5.7.0.p0.120904<br>CDH版本:CDH5.10.041<br>使用root用户对集群进行部署</p>
<h2 id="直接添加所缺jar包"><a href="#直接添加所缺jar包" class="headerlink" title="直接添加所缺jar包"></a>直接添加所缺jar包</h2><h3 id="下载Apache版Spark"><a href="#下载Apache版Spark" class="headerlink" title="下载Apache版Spark"></a>下载Apache版Spark</h3><p>解压后找到jars/目录下的<br><code>hive-cli-1.2.1.spark2.jar</code><br><code>spark-hive-thriftserver_2.11-2.1.0.jar</code><br>上传需要使用spark-sql的机器上</p>
<h3 id="创建spark-sql"><a href="#创建spark-sql" class="headerlink" title="创建spark-sql"></a>创建spark-sql</h3><p>在/opt/cloudera/parcels/SPARK2-2.1.0.cloudera1-1.cdh5.7.0.p0.120904/bin/下新建<strong>spark-sql</strong>文件<br><code>vi /opt/cloudera/parcels/SPARK2-2.1.0.cloudera1-1.cdh5.7.0.p0.120904/bin/spark-sql</code></p>
</blockquote>
<p><figure class="highlight bash"><table><tr><td class="code"><pre><div class="line"><span class="meta">#!/bin/bash</span></div><div class="line">  <span class="comment"># Reference: http://stackoverflow.com/questions/59895/can-a-bash-script-tell-what-directory-its-stored-in</span></div><div class="line">  SOURCE=<span class="string">"<span class="variable">$&#123;BASH_SOURCE[0]&#125;</span>"</span></div><div class="line">  BIN_DIR=<span class="string">"<span class="variable">$( dirname "$SOURCE" )</span>"</span></div><div class="line">  <span class="keyword">while</span> [ -h <span class="string">"<span class="variable">$SOURCE</span>"</span> ]</div><div class="line">  <span class="keyword">do</span></div><div class="line">    SOURCE=<span class="string">"<span class="variable">$(readlink "$SOURCE")</span>"</span></div><div class="line">    [[ <span class="variable">$SOURCE</span> != /* ]] &amp;&amp; SOURCE=<span class="string">"<span class="variable">$DIR</span>/<span class="variable">$SOURCE</span>"</span></div><div class="line">    BIN_DIR=<span class="string">"<span class="variable">$( cd -P "$( dirname "$SOURCE"  )</span>"</span> &amp;&amp; <span class="built_in">pwd</span> )<span class="string">"</span></div><div class="line">  done</div><div class="line">  BIN_DIR="$( <span class="built_in">cd</span> -P <span class="string">"<span class="variable">$( dirname "$SOURCE" )</span>"</span> &amp;&amp; <span class="built_in">pwd</span> )<span class="string">"</span></div><div class="line">  CDH_LIB_DIR=<span class="variable">$BIN_DIR</span>/../../CDH/lib</div><div class="line">  LIB_DIR=<span class="variable">$BIN_DIR</span>/../lib</div><div class="line">export HADOOP_HOME=<span class="variable">$CDH_LIB_DIR</span>/hadoop</div><div class="line"></div><div class="line"># Autodetect JAVA_HOME if not defined</div><div class="line">. <span class="variable">$CDH_LIB_DIR</span>/bigtop-utils/bigtop-detect-javahome</div><div class="line"></div><div class="line">exec <span class="variable">$LIB_DIR</span>/spark2/bin/spark-sql "<span class="variable">$@</span><span class="string">"</span></div></pre></td></tr></table></figure>
</p>
<p>在/opt/cloudera/parcels/SPARK2-2.1.0.cloudera1-1.cdh5.7.0.p0.120904/lib/spark2/bin下新建spark-sql,同时添加之前传的两个jar包<br><code>vi /opt/cloudera/parcels/SPARK2-2.1.0.cloudera1-1.cdh5.7.0.p0.120904/lib/spark2/bin/spark-sql</code><br><figure class="highlight bash"><table><tr><td class="code"><pre><div class="line"><span class="meta">#!/usr/bin/env bash</span></div><div class="line"></div><div class="line"><span class="comment">#</span></div><div class="line"><span class="comment"># Licensed to the Apache Software Foundation (ASF) under one or more</span></div><div class="line"><span class="comment"># contributor license agreements.  See the NOTICE file distributed with</span></div><div class="line"><span class="comment"># this work for additional information regarding copyright ownership.</span></div><div class="line"><span class="comment"># The ASF licenses this file to You under the Apache License, Version 2.0</span></div><div class="line"><span class="comment"># (the "License"); you may not use this file except in compliance with</span></div><div class="line"><span class="comment"># the License.  You may obtain a copy of the License at</span></div><div class="line"><span class="comment">#</span></div><div class="line"><span class="comment">#    http://www.apache.org/licenses/LICENSE-2.0</span></div><div class="line"><span class="comment">#</span></div><div class="line"><span class="comment"># Unless required by applicable law or agreed to in writing, software</span></div><div class="line"><span class="comment"># distributed under the License is distributed on an "AS IS" BASIS,</span></div><div class="line"><span class="comment"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></div><div class="line"><span class="comment"># See the License for the specific language governing permissions and</span></div><div class="line"><span class="comment"># limitations under the License.</span></div><div class="line"><span class="comment">#</span></div><div class="line"></div><div class="line"><span class="keyword">if</span> [ -z <span class="string">"<span class="variable">$&#123;SPARK_HOME&#125;</span>"</span> ]; <span class="keyword">then</span></div><div class="line">  <span class="built_in">source</span> <span class="string">"<span class="variable">$(dirname "$0")</span>"</span>/find-spark-home</div><div class="line"><span class="keyword">fi</span></div><div class="line"></div><div class="line"><span class="built_in">export</span> _SPARK_CMD_USAGE=<span class="string">"Usage: ./bin/spark-sql [options] [cli option]"</span></div><div class="line"><span class="comment">#exec "$&#123;SPARK_HOME&#125;"/bin/spark-submit --class org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver "$@"</span></div><div class="line"><span class="built_in">exec</span> <span class="string">"<span class="variable">$&#123;SPARK_HOME&#125;</span>"</span>/bin/spark-submit --jars /home/manage/spark-hive-thriftserver_2.11-2.1.0.jar,/home/manage/hive-cli-1.2.1.spark2.jar --class org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver <span class="string">"<span class="variable">$@</span>"</span></div></pre></td></tr></table></figure></p>
<p>同时可以设置一个别名指向spark-sql<br><code>alias spark2-sql=&quot;/opt/cloudera/parcels/SPARK2-2.1.0.cloudera1-1.cdh5.7.0.p0.120904/bin/spark-sql&quot;</code></p>
<h3 id="在log4j中添加spark-sql"><a href="#在log4j中添加spark-sql" class="headerlink" title="在log4j中添加spark-sql"></a>在log4j中添加spark-sql</h3><p>路径:/opt/cloudera/parcels/SPARK2-2.1.0.cloudera1-1.cdh5.7.0.p0.120904/lib/spark2/conf<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">log4j.logger.org.apache.spark.sql.SQLContext=ERROR </div><div class="line">log4j.logger.org.apache.spark.sql.catalyst.analysis.Analyzer=ERROR</div></pre></td></tr></table></figure></p>
<h3 id="spark1-6-spark-sql支持"><a href="#spark1-6-spark-sql支持" class="headerlink" title="spark1.6 spark-sql支持"></a>spark1.6 spark-sql支持</h3><p><a href="http://www.javali.org/bigdata/one-trick-on-supporting-sparksql-in-cdh5.html" target="_blank" rel="noopener">spark1.6 spark-sql支持</a><br>其实就是对应的jar包不同,1.6所缺的为spark-assembly-1.6.1-hadoop2.6.0.jar</p>
<h3 id="SparkHiveServer"><a href="#SparkHiveServer" class="headerlink" title="SparkHiveServer"></a>SparkHiveServer</h3><p>直到最近在调研Spark并计划将Spark取代Mapreduce来提升平台的计算效率时，发现Spark-sql能完美的兼容Hive SQL，同时还提供了ThriftServer(就是SparkHiveServer)，不止于此，由于Spark更好的使用了内存，期执行效率是MR/Hive的10倍以上。</p>
<p>其实就是在Spark集群上执行$SPARK_HOME/sbin/start-thriftserver.sh –master=spark://MASTER:7077 就默认开启了10000端口，该服务可以取代hiveserver2，如果与HiveServer2在同一台服务器上，可以先shutdown hiveserver2,再启动spark thriftserver。运行了1个礼拜，服务非常稳定，GC也正常！<br><code>cat start-thriftserver.sh</code><br><figure class="highlight bash"><table><tr><td class="code"><pre><div class="line"><span class="meta">#!/usr/bin/env bash</span></div><div class="line"></div><div class="line"><span class="comment">#</span></div><div class="line"><span class="comment"># Licensed to the Apache Software Foundation (ASF) under one or more</span></div><div class="line"><span class="comment"># contributor license agreements.  See the NOTICE file distributed with</span></div><div class="line"><span class="comment"># this work for additional information regarding copyright ownership.</span></div><div class="line"><span class="comment"># The ASF licenses this file to You under the Apache License, Version 2.0</span></div><div class="line"><span class="comment"># (the "License"); you may not use this file except in compliance with</span></div><div class="line"><span class="comment"># the License.  You may obtain a copy of the License at</span></div><div class="line"><span class="comment">#</span></div><div class="line"><span class="comment">#    http://www.apache.org/licenses/LICENSE-2.0</span></div><div class="line"><span class="comment">#</span></div><div class="line"><span class="comment"># Unless required by applicable law or agreed to in writing, software</span></div><div class="line"><span class="comment"># distributed under the License is distributed on an "AS IS" BASIS,</span></div><div class="line"><span class="comment"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></div><div class="line"><span class="comment"># See the License for the specific language governing permissions and</span></div><div class="line"><span class="comment"># limitations under the License.</span></div><div class="line"><span class="comment">#</span></div><div class="line"></div><div class="line"><span class="comment">#</span></div><div class="line"><span class="comment"># Shell script for starting the Spark SQL Thrift server</span></div><div class="line"></div><div class="line"><span class="comment"># Enter posix mode for bash</span></div><div class="line"><span class="built_in">set</span> -o posix</div><div class="line"></div><div class="line"><span class="keyword">if</span> [ -z <span class="string">"<span class="variable">$&#123;SPARK_HOME&#125;</span>"</span> ]; <span class="keyword">then</span></div><div class="line">  <span class="built_in">export</span> SPARK_HOME=<span class="string">"<span class="variable">$(cd "`dirname "$0"`"/..; pwd)</span>"</span></div><div class="line"><span class="keyword">fi</span></div><div class="line"></div><div class="line"><span class="comment"># <span class="doctag">NOTE:</span> This exact class name is matched downstream by SparkSubmit.</span></div><div class="line"><span class="comment"># Any changes need to be reflected there.</span></div><div class="line">CLASS=<span class="string">"org.apache.spark.sql.hive.thriftserver.HiveThriftServer2"</span></div><div class="line"></div><div class="line"><span class="keyword">function</span> usage &#123;</div><div class="line">  <span class="built_in">echo</span> <span class="string">"Usage: ./sbin/start-thriftserver [options] [thrift server options]"</span></div><div class="line">  pattern=<span class="string">"usage"</span></div><div class="line">  pattern+=<span class="string">"\|Spark assembly has been built with Hive"</span></div><div class="line">  pattern+=<span class="string">"\|NOTE: SPARK_PREPEND_CLASSES is set"</span></div><div class="line">  pattern+=<span class="string">"\|Spark Command: "</span></div><div class="line">  pattern+=<span class="string">"\|======="</span></div><div class="line">  pattern+=<span class="string">"\|--help"</span></div><div class="line"></div><div class="line">  <span class="string">"<span class="variable">$&#123;SPARK_HOME&#125;</span>"</span>/bin/spark-submit --<span class="built_in">help</span> 2&gt;&amp;1 | grep -v Usage 1&gt;&amp;2</div><div class="line">  <span class="built_in">echo</span></div><div class="line">  <span class="built_in">echo</span> <span class="string">"Thrift server options:"</span></div><div class="line">  <span class="string">"<span class="variable">$&#123;SPARK_HOME&#125;</span>"</span>/bin/spark-class <span class="variable">$CLASS</span> --<span class="built_in">help</span> 2&gt;&amp;1 | grep -v <span class="string">"<span class="variable">$pattern</span>"</span> 1&gt;&amp;2</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">if</span> [[ <span class="string">"<span class="variable">$@</span>"</span> = *--<span class="built_in">help</span> ]] || [[ <span class="string">"<span class="variable">$@</span>"</span> = *-h ]]; <span class="keyword">then</span></div><div class="line">  usage</div><div class="line">  <span class="built_in">exit</span> 0</div><div class="line"><span class="keyword">fi</span></div><div class="line"></div><div class="line"><span class="built_in">export</span> SUBMIT_USAGE_FUNCTION=usage</div><div class="line"></div><div class="line"><span class="built_in">exec</span> <span class="string">"<span class="variable">$&#123;SPARK_HOME&#125;</span>"</span>/sbin/spark-daemon.sh submit <span class="variable">$CLASS</span> 1 --name <span class="string">"Thrift JDBC/ODBC Server"</span> <span class="string">"<span class="variable">$@</span>"</span></div></pre></td></tr></table></figure></p>
<p>后来发现只要把缺少的两个jar包导入到<br>cp activation-1.1.1.jar aopalliance-1.0.jar apacheds-i18n-2.0.0-M15.jar apacheds-kerberos-codec-2.0.0-M15.jar api-asn1-api-1.0.0-M20.jar api-util-1.0.0-M20.jar base64-2.3.8.jar bcprov-jdk15on-1.51.jar commons-beanutils-1.7.0.jar commons-beanutils-core-1.8.0.jar commons-configuration-1.6.jar commons-digester-1.8.jar curator-client-2.6.0.jar curator-framework-2.6.0.jar curator-recipes-2.6.0.jar guava-14.0.1.jar guice-3.0.jar guice-servlet-3.0.jar hadoop-annotations-2.6.4.jar hadoop-auth-2.6.4.jar hadoop-client-2.6.4.jar hadoop-common-2.6.4.jar hadoop-hdfs-2.6.4.jar hadoop-mapreduce-client-app-2.6.4.jar hadoop-mapreduce-client-common-2.6.4.jar hadoop-mapreduce-client-core-2.6.4.jar hadoop-mapreduce-client-jobclient-2.6.4.jar hadoop-mapreduce-client-shuffle-2.6.4.jar hadoop-yarn-api-2.6.4.jar hadoop-yarn-client-2.6.4.jar hadoop-yarn-common-2.6.4.jar hadoop-yarn-server-common-2.6.4.jar hadoop-yarn-server-web-proxy-2.6.4.jar hive-beeline-1.2.1.spark2.jar hive-exec-1.2.1.spark2.jar hive-jdbc-1.2.1.spark2.jar htrace-core-3.0.4.jar httpclient-4.5.2.jar jackson-core-asl-1.9.13.jar jackson-mapper-asl-1.9.13.jar java-xmlbuilder-1.0.jar javax.inject-1.jar jaxb-api-2.2.2.jar jets3t-0.9.3.jar jetty-6.1.26.jar jsr305-1.3.9.jar leveldbjni-all-1.8.jar mail-1.4.7.jar mesos-1.0.0-shaded-protobuf.jar mx4j-3.0.2.jar protobuf-java-2.5.0.jar slf4j-api-1.7.16.jar slf4j-log4j12-1.7.16.jar snappy-java-1.1.2.6.jar spark-mesos_2.11-2.1.1.jar stax-api-1.0-2.jar super-csv-2.2.0.jar xercesImpl-2.9.1.jar xmlenc-0.52.jar zookeeper-3.4.6.jar /opt/cloudera/parcels/SPARK2-2.0.0.cloudera2-1.cdh5.7.0.p0.118100/lib/spark2/jars/ </p>
<p>SparkSQL accesses its metadata via the HMS directly, and does not go through a HS2, so it does not truly get covered fully by Sentry. However, in a Sentry setup the HMS is write-protected via the Sentry Authz Plugin added on it, so DDLs are still protected against, but users can still view all metadata (i.e. they can run SHOW TABLES, SHOW DATABASES, etc. and retrieve full listing [1]).</p>
<p>With Sentry HMS plugin and Sentry HDFS ACL Sync enabled, access to tables’ data by Spark programs would be limited to the same rules as your Beeline/other Hive clients would.</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">cp activation-1.1.1.jar aopalliance-1.0.jar apacheds-i18n-2.0.0-M15.jar apacheds-kerberos-codec-2.0.0-M15.jar api-asn1-api-1.0.0-M20.jar api-util-1.0.0-M20.jar base64-2.3.8.jar bcprov-jdk15on-1.51.jar commons-beanutils-1.7.0.jar commons-beanutils-core-1.8.0.jar commons-configuration-1.6.jar commons-digester-1.8.jar curator-client-2.6.0.jar curator-framework-2.6.0.jar curator-recipes-2.6.0.jar guava-14.0.1.jar guice-3.0.jar guice-servlet-3.0.jar hadoop-annotations-2.6.4.jar hadoop-auth-2.6.4.jar hadoop-client-2.6.4.jar hadoop-common-2.6.4.jar hadoop-hdfs-2.6.4.jar hadoop-mapreduce-client-app-2.6.4.jar hadoop-mapreduce-client-common-2.6.4.jar hadoop-mapreduce-client-core-2.6.4.jar hadoop-mapreduce-client-jobclient-2.6.4.jar hadoop-mapreduce-client-shuffle-2.6.4.jar hadoop-yarn-api-2.6.4.jar hadoop-yarn-client-2.6.4.jar hadoop-yarn-common-2.6.4.jar hadoop-yarn-server-common-2.6.4.jar hadoop-yarn-server-web-proxy-2.6.4.jar htrace-core-3.0.4.jar httpclient-4.5.2.jar jackson-core-asl-1.9.13.jar jackson-mapper-asl-1.9.13.jar java-xmlbuilder-1.0.jar javax.inject-1.jar jaxb-api-2.2.2.jar jets3t-0.9.3.jar jetty-6.1.26.jar jsr305-1.3.9.jar leveldbjni-all-1.8.jar mail-1.4.7.jar mesos-1.0.0-shaded-protobuf.jar mx4j-3.0.2.jar protobuf-java-2.5.0.jar slf4j-api-1.7.16.jar slf4j-log4j12-1.7.16.jar snappy-java-1.1.2.6.jar spark-mesos_2.11-2.1.1.jar stax-api-1.0-2.jar super-csv-2.2.0.jar xercesImpl-2.9.1.jar xmlenc-0.52.jar zookeeper-3.4.6.jar /opt/cloudera/parcels/SPARK2-2.0.0.cloudera2-1.cdh5.7.0.p0.118100/lib/spark2/jars/ </div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">hive-beeline-1.2.1.spark2.jar hive-exec-1.2.1.spark2.jar hive-jdbc-1.2.1.spark2.jar </div><div class="line"></div><div class="line"></div><div class="line">cp /opt/spark-2.1.1-bin-hadoop2.6/jars/hive-jdbc-1.2.1.spark2.jar /opt/cloudera/parcels/SPARK2-2.0.0.cloudera2-1.cdh5.7.0.p0.118100/lib/spark2/jars/ </div><div class="line">cp /opt/spark-2.1.1-bin-hadoop2.6/jars/hive-beeline-1.2.1.spark2.jar /opt/cloudera/parcels/SPARK2-2.0.0.cloudera2-1.cdh5.7.0.p0.118100/lib/spark2/jars/ </div><div class="line"></div><div class="line">`rm /opt/cloudera/parcels/SPARK2-2.1.0.cloudera2-1.cdh5.7.0.p0.118100/lib/spark2/jars/hive-exec-1.2.1.spark2.jar`</div><div class="line"></div><div class="line"></div><div class="line">#!/bin/bash</div><div class="line">  SOURCE=&quot;$&#123;BASH_SOURCE[0]&#125;&quot;  #/opt/cloudera/parcels/SPARK2-2.1.0.cloudera1-1.cdh5.7.0.p0.120904/bin/</div><div class="line">  BIN_DIR=&quot;$( dirname &quot;$SOURCE&quot; )&quot; </div><div class="line">  while [ -h &quot;$SOURCE&quot; ]</div><div class="line">  do</div><div class="line">    SOURCE=&quot;$(readlink &quot;$SOURCE&quot;)&quot;</div><div class="line">    [[ $SOURCE != /* ]] &amp;&amp; SOURCE=&quot;$DIR/$SOURCE&quot;</div><div class="line">    BIN_DIR=&quot;$( cd -P &quot;$( dirname &quot;$SOURCE&quot;  )&quot; &amp;&amp; pwd )&quot;</div><div class="line">  done</div><div class="line">  BIN_DIR=&quot;$( cd -P &quot;$( dirname &quot;$SOURCE&quot; )&quot; &amp;&amp; pwd )&quot;</div><div class="line">  CDH_LIB_DIR=$BIN_DIR/../../CDH/lib</div><div class="line">  LIB_DIR=$BIN_DIR/../lib</div><div class="line">export HADOOP_HOME=$CDH_LIB_DIR/hadoop</div><div class="line"></div><div class="line"># Autodetect JAVA_HOME if not defined</div><div class="line">. $CDH_LIB_DIR/bigtop-utils/bigtop-detect-javahome</div><div class="line"></div><div class="line">exec $LIB_DIR/spark2/bin/spark-sql &quot;$@&quot;</div><div class="line"></div><div class="line"></div><div class="line">#!/bin/bash</div><div class="line">export HADOOP_HOME=/opt/cloudera/parcels/CDH/lib/hadoop</div><div class="line">. /opt/cloudera/parcels/CDH/lib/bigtop-utils/bigtop-detect-javahome</div><div class="line">exec $LIB_DIR/spark2/bin/spark-sql &quot;$@&quot;</div></pre></td></tr></table></figure>
</p>
<p>exec $LIB_DIR/spark2/sbin/start-thriftserver.sh –name SparkJDBC –master yarn-client  –num-executors 10 –executor-memory 2g –executor-cores 4 –driver-memory 10g –driver-cores 2  –conf spark.storage.memoryFraction=0.2 –conf spark.shuffle.memoryFraction=0.6 –hiveconf hive.server2.thrift.port=10001 –hiveconf hive.server2.logging.operation.enabled=true –hiveconf hive.server2.authentication.kerberos.principal=hive/ddp-kettle-02.cmdmp.com@CMDMP.COM –hiveconf hive.server2.authentication.kerberos.keytab /root/hiveserver.keytab “$@”</p>
<p>exec $LIB_DIR/spark2/sbin/start-thriftserver.sh –name SparkJDBC –master yarn-client  –hiveconf hive.server2.thrift.port=10001 –hiveconf hive.server2.logging.operation.enabled=true –hiveconf hive.metastore.schema.verification=false –hiveconf hive.server2.authentication.kerberos.principal=hive/ddp-kettle-02.cmdmp.com@CMDMP.COM –hiveconf hive.server2.authentication.kerberos.keytab /root/hiveserver.keytab “$@”</p>
<p>exec $LIB_DIR/spark2/sbin/start-thriftserver.sh –name SparkJDBC –master yarn-client  –hiveconf hive.server2.thrift.port=10000 –hiveconf hive.server2.logging.operation.enabled=true –hiveconf hive.metastore.schema.verification=false –hiveconf spark.sql.thriftServer.incrementalCollect=true –hiveconf hive.server2.authentication.kerberos.principal=hive/ddp-kettle-02.cmdmp.com@CMDMP.COM –hiveconf hive.server2.authentication.kerberos.keytab /root/hiveserver.keytab “$@”</p>
<p>–hiveconf hive.metastore.schema.verification=false<br>–hiveconf spark.sql.thriftServer.incrementalCollect=true<br>–hiveconf hive.support.concurrency=true</p>
<p>master ：指定spark提交模式为yarn-client</p>
<p>hive.server2.thrift.port : 指定thrift server的端口</p>
<p>hive.server2.authentication.kerberos.principal：指定启动thrift server的超级管理员principal，此处超级管理员为hive</p>
<p>hive.server2.authentication.kerberos.keytab : 超级管理员对应的keytab　</p>

      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/python/Django.html" rel="next" title="Django">
                <i class="fa fa-chevron-left"></i> Django
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/CDH/Kerberos MIT/kerberos配置文件.html" rel="prev" title="kerberos配置文件">
                kerberos配置文件 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.jpg"
                alt="Nameless13" />
            
              <p class="site-author-name" itemprop="name">Nameless13</p>
              <p class="site-description motion-element" itemprop="description">─=≡Σ((( つ•̀ω•́)つ，大数据运维工程狮，90后</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">164</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">33</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
            </nav>
          

          

          

          
          

          
          

          
            
          
          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#直接添加所缺jar包"><span class="nav-number">1.</span> <span class="nav-text"><a href="#&#x76F4;&#x63A5;&#x6DFB;&#x52A0;&#x6240;&#x7F3A;jar&#x5305;" class="headerlink" title="&#x76F4;&#x63A5;&#x6DFB;&#x52A0;&#x6240;&#x7F3A;jar&#x5305;"></a>&#x76F4;&#x63A5;&#x6DFB;&#x52A0;&#x6240;&#x7F3A;jar&#x5305;</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#下载Apache版Spark"><span class="nav-number">1.1.</span> <span class="nav-text"><a href="#&#x4E0B;&#x8F7D;Apache&#x7248;Spark" class="headerlink" title="&#x4E0B;&#x8F7D;Apache&#x7248;Spark"></a>&#x4E0B;&#x8F7D;Apache&#x7248;Spark</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#创建spark-sql"><span class="nav-number">1.2.</span> <span class="nav-text"><a href="#&#x521B;&#x5EFA;spark-sql" class="headerlink" title="&#x521B;&#x5EFA;spark-sql"></a>&#x521B;&#x5EFA;spark-sql</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#在log4j中添加spark-sql"><span class="nav-number">1.3.</span> <span class="nav-text"><a href="#&#x5728;log4j&#x4E2D;&#x6DFB;&#x52A0;spark-sql" class="headerlink" title="&#x5728;log4j&#x4E2D;&#x6DFB;&#x52A0;spark-sql"></a>&#x5728;log4j&#x4E2D;&#x6DFB;&#x52A0;spark-sql</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#spark1-6-spark-sql支持"><span class="nav-number">1.4.</span> <span class="nav-text"><a href="#spark1-6-spark-sql&#x652F;&#x6301;" class="headerlink" title="spark1.6 spark-sql&#x652F;&#x6301;"></a>spark1.6 spark-sql&#x652F;&#x6301;</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#SparkHiveServer"><span class="nav-number">1.5.</span> <span class="nav-text"><a href="#SparkHiveServer" class="headerlink" title="SparkHiveServer"></a>SparkHiveServer</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Nameless13</span>

  

  
</div>




  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动 v3.4.3</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/theme-next/hexo-theme-next">NexT.Mist</a> v6.3.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=6.3.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=6.3.0"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=6.3.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=6.3.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=6.3.0"></script>



  



	





  





  










  




  
  
  
  <link rel="stylesheet" href="/lib/algolia-instant-search/instantsearch.min.css">

  
  
  <script src="/lib/algolia-instant-search/instantsearch.min.js"></script>
  

  <script src="/js/src/algolia-search.js?v=6.3.0"></script>



  

  

  

  

  
  

  

  

  

  

  

</body>
</html>
